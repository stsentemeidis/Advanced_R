##################################################################################################
################################ LOADING DATASETS  ###############################################
df_test  <- read.csv('house_price_test.csv')
df_train <- read.csv('house_price_train.csv')

source('install.packages.R')
source('fct_clusters_coord.R')
source('fct_haversine_dist.R')
##################################################################################################
################################ EXPLORATION OF THE DATASET ######################################
str(df_train)
str(df_test)
summary(df_train)
summary(df_test)

# Familiriazing with the dataset.
ggpairs(data=df_train[,-c(1,2,3)])

# Keeping numeric as the common arithmetic type for the data columns.
for (i in colnames(df_train)){
  if (class(df_train[,i]) == 'integer'){
    df_train[,i] <- as.numeric(df_train[,i])
  }
}

for (i in colnames(df_test)){
  if (class(df_test[,i]) == 'integer'){
    df_test[,i] <- as.numeric(df_test[,i])
  }
}

# Converting the date column from factor to date type.
df_train[,'date'] <- as.Date(df_train[,'date'], format = "%m/%d/%Y")
df_test[,'date']  <- as.Date(df_test[,'date'],  format = "%m/%d/%Y")

# Subsetting numerical data.
numeric_data_train<-as.data.frame(data.table(df_train[, sapply(df_train,is.numeric)]))
numeric_data_train <- numeric_data_train[,-c(1)]
numeric_data_test <-as.data.frame(data.table(df_test[, sapply(df_test,is.numeric)]))
numeric_data_test <- numeric_data_test[,-1]

# Checking for missing values.
Amelia::missmap(numeric_data_train, col=c('black','white'))
Amelia::missmap(numeric_data_test , col=c('black','white'))


##################################################################################################
################################ EDA OF THE DATASET ##############################################

# Histogram of the response variable.
ggplot(data=df_train, aes(x=price)) + 
  geom_histogram(col=color3,aes(fill=color3), fill = color3, binwidth = 10000) +
  theme_tufte(base_size = 5, ticks=F)+
  theme(plot.margin = unit(c(10,10,10,10),'pt'),
        axis.title=element_blank(),
        axis.text = element_text(colour = color2, size = 10, family = font2),
        axis.text.x = element_text(hjust = 1, size = 10, family = font2),
        legend.position = 'None',
        plot.background = element_rect(fill = color1)) + 
        scale_y_continuous(labels = comma)+
        scale_x_continuous(labels = comma)

grid.text(unit(0.7, 'npc'), unit(0.9,"npc"), check.overlap = T,just = "left",
          label="Histogram of Prices",
          gp=gpar(col=color3, fontsize=16, fontfamily = font2))

# As you can see, the sale prices are right skewed. This was expected as few people can afford very expensive houses.
# I will keep this in mind, and take measures before modeling.

# Correlation matrix with the response variable.
cor_numVar <- cor(numeric_data_train, use="pairwise.complete.obs") #correlations of all numeric variables

cor_sorted <- as.matrix(sort(cor_numVar[,'price'], decreasing = TRUE))

CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.5)))
cor_numVar <- cor_numVar[CorHigh, CorHigh]

corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt")

# Analyze the 2 or 3 highest correlated variables.
ggplot(data=df_train, aes(x=sqft_living, y=price)) + 
  geom_point(col=color3) + geom_smooth(method = "lm", se=FALSE, color=color2, aes(group=1)) +
  theme_tufte(base_size = 5, ticks=F)+
  theme(plot.margin = unit(c(10,10,10,10),'pt'),
        axis.title=element_blank(),
        axis.text = element_text(colour = color2, size = 10, family = font2),
        axis.text.x = element_text(hjust = 1, size = 10, family = font2),
        legend.position = 'None',
        plot.background = element_rect(fill = color1)) + 
  scale_y_continuous(labels = comma)+
  scale_x_continuous(labels = comma)

grid.text(unit(0.1, 'npc'), unit(0.9,"npc"), check.overlap = T,just = "left",
          label="Relationship of Sqft_living | Price",
          gp=gpar(col=color3, fontsize=16, fontfamily = font2))

########################
ggplot(data=df_train, aes(x=sqft_above, y=sqft_living)) + 
  geom_point(col=color3) + geom_smooth(method = "lm", se=FALSE, color=color2, aes(group=1)) +
  theme_tufte(base_size = 5, ticks=F)+
  theme(plot.margin = unit(c(10,10,10,10),'pt'),
        axis.title=element_blank(),
        axis.text = element_text(colour = color2, size = 10, family = font2),
        axis.text.x = element_text(hjust = 1, size = 10, family = font2),
        legend.position = 'None',
        plot.background = element_rect(fill = color1)) + 
  scale_y_continuous(labels = comma)+
  scale_x_continuous(labels = comma)

grid.text(unit(0.1, 'npc'), unit(0.9,"npc"), check.overlap = T,just = "left",
          label="Relationship of Sqft_living | Sqft_above",
          gp=gpar(col=color3, fontsize=16, fontfamily = font2))

##################################################################################################
################################ MAP OF THE LOCATIONS OF THE HOUSES ##############################
## API SETTINGS
# register_google(key = 'AIzaSyCzcUX4czylxflM0J58r69BbLp6RgrnuhI')
# getOption("ggmap")
# 
# TacomaMap <- get_map(location = c(lon = -122.1, lat = 47.49),
#                       maptype = "watercolor", source = 'google',
#                       zoom = 10,
#                       filename="data/TacomaMap_temp")
# 
# save(TacomaMap, file = 'TacomaMap.rda')

load('data/TacomaMap.rda')

ggmap(TacomaMap) +
  labs(x = '', y = '') +
  theme(legend.position = 'none') +
  scale_color_hue() +
  scale_fill_hue() +
  geom_point(data = df_train, aes(x = long, y = lat), size = 0.5, color = 'blue')

##################################################################################################
################################ TRANSFORM THE DATASET WHEN NEEDEED ##############################

# Extracting date and month.
df_train$month <- format(as.Date(df_train$date), "%m")
df_test$month  <- format(as.Date(df_test$date), "%Y-%m")
df_train$year  <- format(as.Date(df_train$date), "%Y-%m")
df_test$year   <- format(as.Date(df_test$date), "%Y-%m")

# Time differences between

# Distances from hot spots (airport, attractions)
df_train$distance_from_airport <- haversine_dist(df_train, 'long', 'lat', -122.301659, 47.443546)
df_train$distance_from_zoo_acquarium <- haversine_dist(df_train, 'long', 'lat', -122.434110, 47.245885)
df_train$distance_from_museum_of_glass <- haversine_dist(df_train, 'long', 'lat', -122.43366, 47.24556)
df_train$distance_from_train_station <- haversine_dist(df_train, 'long', 'lat', -122.427778, 47.239722)
df_train$distance_from_university_of_wash <- haversine_dist(df_train, 'long', 'lat', -122.427778, 47.239722)
df_train$distance_from_community_college <- haversine_dist(df_train, 'long', 'lat', -122.521920, 47.244109)
df_train$distance_from_university_puget_sound <- haversine_dist(df_train, 'long', 'lat', -122.482893, 47.263680)
df_train$distance_from_cheney_stadium <- haversine_dist(df_train, 'long', 'lat', -122.498138, 47.238098)
df_train$distance_from_port <- haversine_dist(df_train, 'long', 'lat', -122.418487, 47.265181)

df_train$origin = paste0(df_train$lat,",",df_train$long)


library(XML)
library(bitops)
library(RCurl)
latlon2ft <- function(origin,destination){
  xml.url <- paste0('http://maps.googleapis.com/maps/api/distancematrix/xml?origins=',origin,'&destinations=',destination,'&mode=driving&sensor=false')
  xmlfile <- xmlParse(getURL(xml.url))
  dist <- xmlValue(xmlChildren(xpathApply(xmlfile,"//distance")[[1]])$value)
  distance <- as.numeric(sub(" km","",dist))
  ft <- distance/1000 # FROM METER TO FEET
  return(ft)
}

df_train$drive_dist_airport <- latlon2ft(origin="47.3719,-122.215",destination="47.245885,-122.434110")

# Clustering coordinates with radius
clustering_coords <- clusters_coord(df_train[,c('id', 'lat', 'long')], 5, 'lat', 'long')
clustering_coords <- NA

# Changing some numeric to factor variables.

# Detecting and fixing skewness. Acceptable test limits (-2,2)
for (i in colnames(numeric_data_train)){
  hist(numeric_data_train[,i], col = "tomato",main = i)
  skewness(numeric_data_train[,i])
}

# Scaling variables from 0 to 1 
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
for (i in colnames(numeric_data_train)){
  df_train[,i] <- range01(df_train[,i])
}

for (i in colnames(numeric_data_test)){
  df_test[,i] <- range01(df_test[,i])
}

# Detecting Outliers